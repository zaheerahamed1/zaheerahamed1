{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMc5Pe_Oaz8O"
      },
      "outputs": [],
      "source": [
        "# Create a basic Python script for Medical Document Search using Retrieval-Augmented Generation (RAG)\n",
        "rag_script = \"\"\"\n",
        "import os\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "import logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import openai\n",
        "\n",
        "# Setup\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # Replace with your API key\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Initialize embedding model and QA model\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "def load_documents(file_path):\n",
        "    logging.info(\"Loading documents...\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "def embed_documents(docs):\n",
        "    logging.info(\"Embedding documents...\")\n",
        "    return embedding_model.encode(docs, convert_to_tensor=False)\n",
        "\n",
        "def build_faiss_index(embeddings):\n",
        "    logging.info(\"Building FAISS index...\")\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "def retrieve_documents(query, index, doc_embeddings, docs, top_k=3):\n",
        "    logging.info(\"Retrieving relevant documents...\")\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    _, indices = index.search(np.array(query_embedding), top_k)\n",
        "    return [docs[i] for i in indices[0]]\n",
        "\n",
        "def generate_answer(context, query):\n",
        "    logging.info(\"Generating answer with RAG...\")\n",
        "    prompt = f\"Use the context below to answer the question.\\n\\nContext: {context}\\n\\nQuestion: {query}\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "def run_rag_pipeline(query, docs_df):\n",
        "    docs = docs_df['document'].tolist()\n",
        "    doc_embeddings = embed_documents(docs)\n",
        "    faiss_index = build_faiss_index(np.array(doc_embeddings))\n",
        "    top_docs = retrieve_documents(query, faiss_index, doc_embeddings, docs)\n",
        "    context = \"\\\\n\\\\n\".join(top_docs)\n",
        "    answer = generate_answer(context, query)\n",
        "    return answer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    docs_path = \"medical_documents.csv\"  # Expecting a 'document' column\n",
        "    docs_df = load_documents(docs_path)\n",
        "    user_query = input(\"Enter your medical query: \")\n",
        "    result = run_rag_pipeline(user_query, docs_df)\n",
        "    print(\"\\\\nAnswer:\")\n",
        "    print(result)\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a file\n",
        "file_path = \"/mnt/data/medical_rag_search.py\"\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(rag_script)\n",
        "\n",
        "file_path\n"
      ]
    }
  ]
}